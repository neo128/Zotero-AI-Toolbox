[PIPELINE] → watch: since_hours=24.0 top_k=10 min_score=0.3
[watch-import] [INFO] Started watch. since_hours=24.0 (→ days=1.00) top_k=10 min_score=0.3
[watch-import] [HF] daily fetched=5 from date/2025-11-25
[watch-import] [HF] weekly fetched=20 from week/2025-W48
[watch-import] [HF] monthly fetched=50 from month/2025-11
[watch-import] [INFO] Building library index for dedupe...
[watch-import] [INFO] Library index sizes: DOI=76 arXiv=874 URL=1049 TY=1058
[watch-import] [TAG] embodied_ai 'embodied_ai｜具身智能' keywords=5
[watch-import] [SCORE] tag=embodied_ai total=0 selected=0
[watch-import] [TAG] sim2real 'sim2real｜模拟到现实' keywords=5
[watch-import] [SCORE] tag=sim2real total=0 selected=0
[watch-import] [TAG] teleoperation 'teleoperation｜遥操作' keywords=5
[watch-import] [SCORE] tag=teleoperation total=1 selected=0
[watch-import] [TAG] robotic_navigation 'robotic_navigation｜机器人导航' keywords=5
[watch-import] [HF] robotic_navigation matched 4 trending papers.
[watch-import] [HF-OVERRIDE] Added 'IterResearch: Rethinking Long-Horizon Agents via Markovian State
[watch-import]   Reconstructio' despite score=0.14
[watch-import] [HF-OVERRIDE] Added 'π_RL: Online RL Fine-tuning for Flow-based
[watch-import]   Vision-Language-Action Models' despite score=0.08
[watch-import] [SCORE] tag=robotic_navigation total=44 selected=4
[watch-import] [COL] ensured collection 'robotic_navigation｜机器人导航' → MCGEU54N
[watch-import] [SKIP] duplicate Thinking with Video: Video Generation as a Promising Multimodal
[watch-import]   Reasoning Para (arxiv:2511.04570)
[watch-import] [SKIP] duplicate Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds (arxiv:2511.08892)
[watch-import] [SKIP] duplicate IterResearch: Rethinking Long-Horizon Agents via Markovian State
[watch-import]   Reconstructio (arxiv:2511.07327)
[watch-import] [SKIP] duplicate π_RL: Online RL Fine-tuning for Flow-based
[watch-import]   Vision-Language-Action Models (arxiv:2510.25889)
[watch-import] [TAG] robotic_manipulation 'robotic_manipulation｜机器人操作' keywords=5
[watch-import] [HF] robotic_manipulation matched 5 trending papers.
[watch-import] [HF-OVERRIDE] Added 'GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization' despite score=0.24
[watch-import] [HF-OVERRIDE] Added 'ThinkMorph: Emergent Properties in Multimodal Interleaved
[watch-import]   Chain-of-Thought Rea' despite score=0.18
[watch-import] [SCORE] tag=robotic_manipulation total=15 selected=3
[watch-import] [COL] ensured collection 'robotic_manipulation｜机器人操作' → VPMXKEIX
[watch-import] [SKIP] duplicate Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds (arxiv:2511.08892)
[watch-import] [SKIP] duplicate GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization (arxiv:2511.15705)
[watch-import] [SKIP] duplicate ThinkMorph: Emergent Properties in Multimodal Interleaved
[watch-import]   Chain-of-Thought Rea (doi:10.48550/arxiv.2510.27492)
[watch-import] [TAG] robotic_grasping 'robotic_grasping｜机器人抓取' keywords=5
[watch-import] [SCORE] tag=robotic_grasping total=0 selected=0
[watch-import] [TAG] vision_language_model 'vision_language_model｜视觉语言模型' keywords=5
[watch-import] [HF] vision_language_model matched 13 trending papers.
[watch-import] [HF-OVERRIDE] Added 'VIDEOP2R: Video Understanding from Perception to Reasoning' despite score=0.28
[watch-import] [HF-OVERRIDE] Added 'VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual
[watch-import]   Representatio' despite score=0.26
[watch-import] [SCORE] tag=vision_language_model total=38 selected=4
[watch-import] [COL] ensured collection 'vision_language_model｜视觉语言模型' → QVF9KXGQ
[watch-import] [SKIP] duplicate Thinking with Video: Video Generation as a Promising Multimodal
[watch-import]   Reasoning Para (arxiv:2511.04570)
[watch-import] [SKIP] duplicate Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds (arxiv:2511.08892)
[watch-import] [SKIP] duplicate VIDEOP2R: Video Understanding from Perception to Reasoning (arxiv:2511.11113)
[watch-import] [SKIP] duplicate VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual
[watch-import]   Representatio (arxiv:2511.02778)
[watch-import] [TAG] vision_language_action_model 'vision_language_action_model｜视觉语言动作模型' keywords=4
[watch-import] [HF] vision_language_action_model matched 3 trending papers.
[watch-import] [HF-OVERRIDE] Added 'Don't Blind Your VLA: Aligning Visual Representations for OOD
[watch-import]   Generalization' despite score=0.23
[watch-import] [HF-OVERRIDE] Added 'RynnVLA-002: A Unified Vision-Language-Action and World Model' despite score=0.13
[watch-import] [SCORE] tag=vision_language_action_model total=8 selected=2
[watch-import] [COL] ensured collection 'vision_language_action_model｜视觉语言动作模型' → QXJMF6GC
[watch-import] [SKIP] duplicate Don't Blind Your VLA: Aligning Visual Representations for OOD
[watch-import]   Generalization (arxiv:2510.25616)
[watch-import] [SKIP] duplicate RynnVLA-002: A Unified Vision-Language-Action and World Model (arxiv:2511.17502)
[watch-import] [TAG] large_language_model 'large_language_model｜大语言模型' keywords=4
[watch-import] [HF] large_language_model matched 30 trending papers.
[watch-import] [HF-OVERRIDE] Added 'Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story' despite score=0.28
[watch-import] [HF-OVERRIDE] Added 'General Agentic Memory Via Deep Research' despite score=0.25
[watch-import] [SCORE] tag=large_language_model total=70 selected=3
[watch-import] [COL] ensured collection 'large_language_model｜大语言模型' → 2M7PTRS5
[watch-import] [ADD] General Agentic Memory Via Deep Research → large_language_model｜大语言模型 [6QFR97KG]
[watch-import] [ATTACH] PDF linked for 6QFR97KG
[watch-import] [SKIP] duplicate Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story (arxiv:2511.15210)
[watch-import] [SKIP] duplicate General Agentic Memory Via Deep Research (arxiv:2511.18423)
[watch-import] [TAG] foundation_model 'foundation_model｜基础模型' keywords=4
[watch-import] [HF] foundation_model matched 1 trending papers.
[watch-import] [SCORE] tag=foundation_model total=1 selected=1
[watch-import] [COL] ensured collection 'foundation_model｜基础模型' → XHCMX3G4
[watch-import] [SKIP] duplicate Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation (arxiv:2511.14993)
[watch-import] [TAG] dexterous_hand 'dexterous_hand｜灵巧机械手' keywords=4
[watch-import] [SCORE] tag=dexterous_hand total=0 selected=0
[watch-import] [TAG] humanoid_robot 'humanoid_robot｜类人机器人' keywords=4
[watch-import] [SCORE] tag=humanoid_robot total=1 selected=0
[watch-import] [TAG] quadruped_robot 'quadruped_robot｜四足机器人' keywords=3
[watch-import] [SCORE] tag=quadruped_robot total=0 selected=0
[watch-import] [TAG] robotic_arm 'robotic_arm｜机械臂' keywords=3
[watch-import] [SCORE] tag=robotic_arm total=0 selected=0
[watch-import] [TAG] reinforcement_learning 'reinforcement_learning｜强化学习' keywords=4
[watch-import] [HF] reinforcement_learning matched 50 trending papers.
[watch-import] [HF-OVERRIDE] Added 'OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and ' despite score=0.30
[watch-import] [HF-OVERRIDE] Added 'One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter' despite score=0.30
[watch-import] [SCORE] tag=reinforcement_learning total=58 selected=9
[watch-import] [COL] ensured collection 'reinforcement_learning｜强化学习' → 8S3SWIMS
[watch-import] [SKIP] duplicate General Agentic Memory Via Deep Research (arxiv:2511.18423)
[watch-import] [SKIP] duplicate Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation (arxiv:2511.14993)
[watch-import] [SKIP] duplicate Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds (arxiv:2511.08892)
[watch-import] [SKIP] duplicate MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents v (arxiv:2511.11793)
[watch-import] [SKIP] duplicate P1: Mastering Physics Olympiads with Reinforcement Learning (arxiv:2511.13612)
[watch-import] [SKIP] duplicate Diffusion Language Models are Super Data Learners (arxiv:2511.03276)
[watch-import] [SKIP] duplicate Tiny Model, Big Logic: Diversity-Driven Optimization Elicits Large-Model
[watch-import]   Reaso (arxiv:2511.06221)
[watch-import] [SKIP] duplicate OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and  (arxiv:2511.16334)
[watch-import] [SKIP] duplicate One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter (arxiv:2511.10629)
[watch-import] [TAG] imitation_learning 'imitation_learning｜模仿学习' keywords=5
[watch-import] [SCORE] tag=imitation_learning total=0 selected=0
[watch-import] [TAG] world_model 'world_model｜世界模型' keywords=4
[watch-import] [HF] world_model matched 2 trending papers.
[watch-import] [HF-OVERRIDE] Added 'RynnVLA-002: A Unified Vision-Language-Action and World Model' despite score=0.13
[watch-import] [HF-OVERRIDE] Added 'PAN: A World Model for General, Interactable, and Long-Horizon World Simulation' despite score=0.11
[watch-import] [SCORE] tag=world_model total=2 selected=2
[watch-import] [COL] ensured collection 'world_model｜世界模型' → 4R62EWKD
[watch-import] [SKIP] duplicate RynnVLA-002: A Unified Vision-Language-Action and World Model (arxiv:2511.17502)
[watch-import] [SKIP] duplicate PAN: A World Model for General, Interactable, and Long-Horizon World Simulation (arxiv:2511.09057)
[watch-import] [TAG] simulator 'simulator｜仿真平台' keywords=5
[watch-import] [SCORE] tag=simulator total=50 selected=0
[watch-import] [TAG] motion_planning 'motion_planning｜运动规划' keywords=4
[watch-import] [SCORE] tag=motion_planning total=0 selected=0
[watch-import] [TAG] task_planning 'task_planning｜任务规划' keywords=4
[watch-import] [HF] task_planning matched 3 trending papers.
[watch-import] [HF-OVERRIDE] Added 'Grounding Computer Use Agents on Human Demonstrations' despite score=0.27
[watch-import] [HF-OVERRIDE] Added 'Part-X-MLLM: Part-aware 3D Multimodal Large Language Model' despite score=0.13
[watch-import] [SCORE] tag=task_planning total=5 selected=2
[watch-import] [COL] ensured collection 'task_planning｜任务规划' → IDXJKRDJ
[watch-import] [SKIP] duplicate Grounding Computer Use Agents on Human Demonstrations (arxiv:2511.07332)
[watch-import] [SKIP] duplicate Part-X-MLLM: Part-aware 3D Multimodal Large Language Model (arxiv:2511.13647)
[watch-import] [TAG] code_based_task_planning 'code_based_task_planning｜代码任务规划' keywords=4
[watch-import] [SCORE] tag=code_based_task_planning total=0 selected=0
[watch-import] [TAG] language_based_task_planning 'language_based_task_planning｜语言任务规划' keywords=3
[watch-import] [SCORE] tag=language_based_task_planning total=0 selected=0
[watch-import] [TAG] end_to_end_task_planning 'end_to_end_task_planning｜端到端任务规划' keywords=3
[watch-import] [SCORE] tag=end_to_end_task_planning total=0 selected=0
[watch-import] [TAG] grounded_task_planning 'grounded_task_planning｜具身语义任务规划' keywords=3
[watch-import] [SCORE] tag=grounded_task_planning total=0 selected=0
[watch-import] [TAG] transformer_policy 'transformer_policy｜Transformer控制策略' keywords=4
[watch-import] [SCORE] tag=transformer_policy total=0 selected=0
[watch-import] [TAG] diffusion_policy 'diffusion_policy｜扩散策略学习' keywords=3
[watch-import] [SCORE] tag=diffusion_policy total=0 selected=0
[watch-import] [TAG] 3d_vision '3d_vision｜3D视觉感知' keywords=4
[watch-import] [SCORE] tag=3d_vision total=0 selected=0
[watch-import] [TAG] point_based_action 'point_based_action｜基于点的控制' keywords=4
[watch-import] [SCORE] tag=point_based_action total=0 selected=0
[watch-import] [TAG] chain_of_thought 'chain_of_thought｜链式推理' keywords=4
[watch-import] [SCORE] tag=chain_of_thought total=0 selected=0
[watch-import] [INFO] Recorded 1 new items → /Users/neoone/code/Zotero/.data/new_items_watch.json
[watch-import] [INFO] Done. Summary: {"candidates": 1, "added": 1, "skipped": 29, "updated": 0, "hf_candidates": 111, "hf_overrides": 16}
[watch-import] [INFO] Report → /Users/neoone/code/Zotero/reports/watch_20251125_164636.json
[PIPELINE] ✓ watch completed
[PIPELINE] → pdf: since_hours=24.0 limit=∞
[fetch-pdfs] [TRY] 6QFR97KG ← existing attachment link: https://arxiv.org/pdf/2511.18423.pdf
[fetch-pdfs] [OK] Linked local PDF for 6QFR97KG
[fetch-pdfs] [INFO] Item 9PSIWU8H already has local PDF attachments; skipping.
[fetch-pdfs] [INFO] Item TAS5E5H2 already has local PDF attachments; skipping.
[fetch-pdfs] [INFO] Completed. PDFs added: 1, remaining without PDF: 0.
[PIPELINE] ✓ pdf completed
[PIPELINE] → dedupe: limit=∞ since_hours=24.0
[dedupe] [INFO] Scanned 3 top-level items (after time filter).
[dedupe] [INFO] No duplicates detected with the current heuristic.
[PIPELINE] ✓ dedupe completed
[PIPELINE] → summary: limit=200 since_hours=24.0
[summaries] [INFO] Fetched 200 Zotero items before time-window filtering.
[summaries] [INFO] 11 items remain after applying modified-since 24.0h window.
[summaries] [INFO] Processing General_Agentic_Memory_Via_Deep_Research.pdf (SE2WB648)
[summaries]   - Reading General_Agentic_Memory_Via_Deep_Research.pdf
[summaries]     [OK] Note created.
[summaries] [INFO] Processing PDF (ZT4S9QQA)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Processing General Agentic Memory Via Deep Research (6QFR97KG)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Processing G9NDAW2D (G9NDAW2D)
[summaries] [WARN] No local PDF attachments for G9NDAW2D; children types: none
[summaries] [INFO] Processing 2N2TCNHN (2N2TCNHN)
[summaries] [WARN] No local PDF attachments for 2N2TCNHN; children types: none
[summaries] [INFO] Processing MergeDNA__Context-aware_Genome_Modeling_with_Dynamic_Tokenization_through_Token_.pdf (F4W847A8)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Processing Unveiling_Intrinsic_Dimension_of_Texts__from_Academic_Abstract_to_Creative_Story.pdf (RA4A2HVR)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Processing PDF (VD5QRU2G)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Processing MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token Merging (9PSIWU8H)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Processing PDF (ZF5283M9)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Processing Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story (TAS5E5H2)
[summaries]     [SKIP] Existing AI总结 note found; skipping this item.
[summaries] [INFO] Completed. Items scanned: 11, notes created: 1.
[PIPELINE] ✓ summary completed
[PIPELINE] → abstracts: limit=∞ since_hours=24.0
[abstracts] [INFO] Completed. Items scanned: 1106, updated: 0, missing abstract after lookup: 0.
[PIPELINE] ✓ abstracts completed
[PIPELINE] → notion: limit=500 since_hours=24.0
[notion-sync] [ERR] Notion API error for 'General Agentic Memory Via Deep Research': 400 Client Error: Bad Request for url: https://api.notion.com/v1/pages
[notion-sync] [ERR] Notion API error for 'MergeDNA: Context-aware Genome Modeling with Dynamic Tokenization through Token ': 400 Client Error: Bad Request for url: https://api.notion.com/v1/pages
[notion-sync] [ERR] Notion API error for 'Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story': 400 Client Error: Bad Request for url: https://api.notion.com/v1/pages
[notion-sync] [INFO] Completed. Scanned=3 created=0 updated=0
[PIPELINE] ✓ notion completed
{
  "watch": {
    "name": "watch-import",
    "command": [
      "/Users/neoone/miniconda3/bin/python",
      "/Users/neoone/code/Zotero/scripts/watch_and_import_papers.py",
      "--tags",
      "/Users/neoone/code/Zotero/tag.json",
      "--since-days",
      "0",
      "--since-hours",
      "24.0",
      "--top-k",
      "10",
      "--min-score",
      "0.3",
      "--log-file",
      "/Users/neoone/code/Zotero/logs/watch_20251125_164636.log",
      "--report-json",
      "/Users/neoone/code/Zotero/reports/watch_20251125_164636.json",
      "--create-collections"
    ],
    "artifacts": {
      "log": "/Users/neoone/code/Zotero/logs/watch_20251125_164636.log",
      "report": "/Users/neoone/code/Zotero/reports/watch_20251125_164636.json",
      "report_data": {
        "started_at": "2025-11-25T16:46:36.810317",
        "params": {
          "since_days": 0,
          "since_hours": 24.0,
          "top_k": 10,
          "min_score": 0.3,
          "create_collections": true,
          "fill_missing": false,
          "dry_run": false,
          "use_hf_papers": true,
          "hf_weight": 0.3
        },
        "tags": {
          "embodied_ai": {
            "label": "embodied_ai｜具身智能",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "sim2real": {
            "label": "sim2real｜模拟到现实",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "teleoperation": {
            "label": "teleoperation｜遥操作",
            "candidates": 1,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "robotic_navigation": {
            "label": "robotic_navigation｜机器人导航",
            "candidates": 44,
            "added": 0,
            "skipped": 4,
            "updated": 0,
            "hf_candidates": 4,
            "hf_overrides": 2
          },
          "robotic_manipulation": {
            "label": "robotic_manipulation｜机器人操作",
            "candidates": 15,
            "added": 0,
            "skipped": 3,
            "updated": 0,
            "hf_candidates": 5,
            "hf_overrides": 2
          },
          "robotic_grasping": {
            "label": "robotic_grasping｜机器人抓取",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "vision_language_model": {
            "label": "vision_language_model｜视觉语言模型",
            "candidates": 38,
            "added": 0,
            "skipped": 4,
            "updated": 0,
            "hf_candidates": 13,
            "hf_overrides": 2
          },
          "vision_language_action_model": {
            "label": "vision_language_action_model｜视觉语言动作模型",
            "candidates": 8,
            "added": 0,
            "skipped": 2,
            "updated": 0,
            "hf_candidates": 3,
            "hf_overrides": 2
          },
          "large_language_model": {
            "label": "large_language_model｜大语言模型",
            "candidates": 70,
            "added": 1,
            "skipped": 2,
            "updated": 0,
            "hf_candidates": 30,
            "hf_overrides": 2
          },
          "foundation_model": {
            "label": "foundation_model｜基础模型",
            "candidates": 1,
            "added": 0,
            "skipped": 1,
            "updated": 0,
            "hf_candidates": 1,
            "hf_overrides": 0
          },
          "dexterous_hand": {
            "label": "dexterous_hand｜灵巧机械手",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "humanoid_robot": {
            "label": "humanoid_robot｜类人机器人",
            "candidates": 1,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "quadruped_robot": {
            "label": "quadruped_robot｜四足机器人",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "robotic_arm": {
            "label": "robotic_arm｜机械臂",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "reinforcement_learning": {
            "label": "reinforcement_learning｜强化学习",
            "candidates": 58,
            "added": 0,
            "skipped": 9,
            "updated": 0,
            "hf_candidates": 50,
            "hf_overrides": 2
          },
          "imitation_learning": {
            "label": "imitation_learning｜模仿学习",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "world_model": {
            "label": "world_model｜世界模型",
            "candidates": 2,
            "added": 0,
            "skipped": 2,
            "updated": 0,
            "hf_candidates": 2,
            "hf_overrides": 2
          },
          "simulator": {
            "label": "simulator｜仿真平台",
            "candidates": 50,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "motion_planning": {
            "label": "motion_planning｜运动规划",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "task_planning": {
            "label": "task_planning｜任务规划",
            "candidates": 5,
            "added": 0,
            "skipped": 2,
            "updated": 0,
            "hf_candidates": 3,
            "hf_overrides": 2
          },
          "code_based_task_planning": {
            "label": "code_based_task_planning｜代码任务规划",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "language_based_task_planning": {
            "label": "language_based_task_planning｜语言任务规划",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "end_to_end_task_planning": {
            "label": "end_to_end_task_planning｜端到端任务规划",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "grounded_task_planning": {
            "label": "grounded_task_planning｜具身语义任务规划",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "transformer_policy": {
            "label": "transformer_policy｜Transformer控制策略",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "diffusion_policy": {
            "label": "diffusion_policy｜扩散策略学习",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "3d_vision": {
            "label": "3d_vision｜3D视觉感知",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "point_based_action": {
            "label": "point_based_action｜基于点的控制",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          },
          "chain_of_thought": {
            "label": "chain_of_thought｜链式推理",
            "candidates": 0,
            "added": 0,
            "skipped": 0,
            "updated": 0,
            "hf_candidates": 0,
            "hf_overrides": 0
          }
        },
        "summary": {
          "candidates": 1,
          "added": 1,
          "skipped": 29,
          "updated": 0,
          "hf_candidates": 111,
          "hf_overrides": 16
        },
        "errors": [],
        "hf_sources": {
          "daily": 5,
          "weekly": 20,
          "monthly": 50
        },
        "finished_at": "2025-11-25T16:57:10.471918"
      }
    }
  },
  "pdf": {
    "name": "fetch-pdfs",
    "command": [
      "/Users/neoone/miniconda3/bin/python",
      "/Users/neoone/code/Zotero/scripts/fetch_missing_pdfs.py",
      "--since-hours",
      "24.0",
      "--new-items-json",
      "/Users/neoone/code/Zotero/.data/new_items_watch.json"
    ],
    "artifacts": {}
  },
  "dedupe": {
    "name": "dedupe",
    "command": [
      "/Users/neoone/miniconda3/bin/python",
      "/Users/neoone/code/Zotero/scripts/merge_zotero_duplicates.py",
      "--group-by",
      "auto",
      "--modified-since-hours",
      "24.0"
    ],
    "artifacts": {}
  },
  "summary": {
    "name": "summaries",
    "command": [
      "/Users/neoone/miniconda3/bin/python",
      "/Users/neoone/code/Zotero/scripts/summarize_zotero_with_doubao.py",
      "--limit",
      "200",
      "--max-pages",
      "80",
      "--max-chars",
      "80000",
      "--note-tag",
      "AI总结",
      "--summary-dir",
      "/Users/neoone/code/Zotero/summaries",
      "--recursive",
      "--insert-note",
      "--modified-since-hours",
      "24.0"
    ],
    "artifacts": {
      "summary_dir": "/Users/neoone/code/Zotero/summaries"
    }
  },
  "abstract": {
    "name": "abstracts",
    "command": [
      "/Users/neoone/miniconda3/bin/python",
      "/Users/neoone/code/Zotero/scripts/enrich_zotero_abstracts.py",
      "--modified-since-hours",
      "24.0"
    ],
    "artifacts": {}
  },
  "notion": {
    "name": "notion-sync",
    "command": [
      "/Users/neoone/miniconda3/bin/python",
      "/Users/neoone/code/Zotero/scripts/sync_zotero_to_notion.py",
      "--limit",
      "500",
      "--tag-file",
      "/Users/neoone/code/Zotero/tag.json",
      "--recursive",
      "--skip-untitled",
      "--enrich-with-doubao",
      "--since-hours",
      "24.0"
    ],
    "artifacts": {}
  }
}
